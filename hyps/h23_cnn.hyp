


#filename: h23_cnn.hyp

# used for RL training of DDQN for connect-four game play with CNN layers

start_episode = 0
end_episode = 100002
max_replay_buffer_size = 1000000

agent1_learning_rate = 0.00025
agent2_learning_rate = 0.00025

# Convolutional layer configurations: (out_channels, kernel_size, stride)
cnn_a1 = [(16, 3, 1), (32, 3, 1)]
cnn_a2 = [(16, 3, 1), (32, 3, 1)]

# Fully connected layer dimensions for each agent
fc_a1 = [2688, 128, 64]
fc_a2 = [2688, 128, 64]

NOTE: Calculate the output size for each convolutional layer using the formula:
CNN_Output_Size is equal to ((Input_Size−Kernel_Size+2×Padding)/Stride)+1
Make sure the FC_input_size matches the CNN_output_Size



console_status_interval = 500
tensorboard_status_interval = 100
ckpt_interval = 2500

render_game_at = [1, 250001]

a1_epsilon_start = 0.1
a1_epsilon_end = 0.01
a2_epsilon_start = 0.1
a2_epsilon_end = 0.01

batch_size = 32
gamma = 0.99

