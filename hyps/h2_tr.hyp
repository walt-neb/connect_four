# Hyperparameters

num_epochs = 15000
embed_dim = 128
n_heads = 2
ff_dim = 128
n_layers = 2
dropout = 0.1
capacity = 8000
batch_size = 64
gamma = 0.99
learning_rate = .00005
epsilon = .10  
epsilon_min = 0.01  
epsilon_decay = 0.999
output_dim = 7
input_dim = 42


----------- Training Results ----------------
Started training at: 	2024-05-28  20:41:50
Ended training at: 	2024-05-28  20:48:39
Total training time:  0:06:48.228735
epoch count: 999
end epsilon: 0.00998645168764533
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	10000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.995



----------- Training Results ----------------
Started training at: 	2024-05-28  22:16:37
Ended training at: 	2024-05-28  22:24:50
Total training time:  0:08:13.954758
epoch count: 999
end epsilon: 0.00998645168764533
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	1000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.995



----------- Training Results ----------------
Started training at: 	2024-05-28  22:32:30
Ended training at: 	2024-05-29  01:01:08
Total training time:  2:28:37.736218
epoch count: 19999
end epsilon: 0.009985630741373389
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.998



----------- Training Results ----------------
Started training at: 	2024-05-29  05:52:10
Ended training at: 	2024-05-29  06:29:13
Total training time:  0:37:03.390807
epoch count: 6597
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999

**Exited training loop early at episode 6597
start_episode = 6597



----------- Training Results ----------------
Started training at: 	2024-05-29  06:42:27
Ended training at: 	2024-05-29  07:01:16
Total training time:  0:18:49.222222
epoch count: 4317
end epsilon: 0.013297749874793902
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	6597

**Exited training loop early at episode 4317
start_episode = 4317



----------- Training Results ----------------
Started training at: 	2024-05-29  07:16:03
Ended training at: 	2024-05-29  09:46:15
Total training time:  2:30:11.505052
epoch count: 6828
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	4317

**Exited training loop early at episode 6828
start_episode = 6828



----------- Training Results ----------------
Started training at: 	2024-05-29  20:51:36
Ended training at: 	2024-05-29  20:51:55
Total training time:  0:00:19.390006
epoch count: 30
end epsilon: 0.9694605362958227
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	4
		ff_dim :	512
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	6828

**Exited training loop early at episode 30
start_episode = 30



----------- Training Results ----------------
Started training at: 	2024-05-29  20:52:08
Ended training at: 	2024-05-30  06:05:44
Total training time:  9:13:35.856809
epoch count: 26794
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	4
		ff_dim :	512
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	64
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	30

**Exited training loop early at episode 26794
start_episode = 26794



----------- Training Results ----------------
Started training at: 	2024-05-30  08:04:00
Ended training at: 	2024-05-30  11:09:03
Total training time:  3:05:03.288226
epoch count: 19999
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	2
		ff_dim :	128
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	26794



----------- Training Results ----------------
Started training at: 	2024-05-30  21:05:33
Ended training at: 	2024-05-31  02:06:06
Total training time:  5:00:32.895149
epoch count: 19999
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	2
		ff_dim :	128
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	26794



----------- Training Results ----------------
Started training at: 	2024-05-31  10:59:09
Ended training at: 	2024-05-31  12:01:22
Total training time:  1:02:13.016417
epoch count: 4999
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	2
		ff_dim :	128
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		num_epochs :	5000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	26794



----------- Training Results ----------------
Started training at: 	2024-05-31  14:23:45
Ended training at: 	2024-05-31  17:15:57
Total training time:  2:52:12.201178
epoch count: 14999
end epsilon: 0.009994334856146604
Input Parameters:
		num_epochs :	15000
		embed_dim :	128
		n_heads :	2
		ff_dim :	128
		n_layers :	2
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		learning_rate :	5e-05
		epsilon :	0.1
		epsilon_min :	0.01
		epsilon_decay :	0.999
		output_dim :	7
		input_dim :	42
		start_episode :	26794

