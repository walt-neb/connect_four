# Hyperparameters

num_epochs = 10000
embed_dim = 256
n_heads = 2
ff_dim = 256
n_layers = 4
dropout = 0.1
capacity = 8000
batch_size = 64
gamma = 0.99
learning_rate = .00005
epsilon = 1.0  
epsilon_min = 0.01  
epsilon_decay = 0.999

input_dim = 42
output_dim = 7


----------- Training Results ----------------
Started training at: 	2024-05-28  20:41:50
Ended training at: 	2024-05-28  20:48:39
Total training time:  0:06:48.228735
epoch count: 999
end epsilon: 0.00998645168764533
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	10000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.995



----------- Training Results ----------------
Started training at: 	2024-05-28  22:16:37
Ended training at: 	2024-05-28  22:24:50
Total training time:  0:08:13.954758
epoch count: 999
end epsilon: 0.00998645168764533
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	1000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.995



----------- Training Results ----------------
Started training at: 	2024-05-28  22:32:30
Ended training at: 	2024-05-29  01:01:08
Total training time:  2:28:37.736218
epoch count: 19999
end epsilon: 0.009985630741373389
Input Parameters:
		input_dim :	42
		embed_dim :	128
		n_heads :	4
		ff_dim :	512
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	10000
		batch_size :	32
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	0.0001
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.998



----------- Training Results ----------------
Started training at: 	2024-05-29  05:52:10
Ended training at: 	2024-05-29  06:29:13
Total training time:  0:37:03.390807
epoch count: 6597
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999

**Exited training loop early at episode 6597
start_episode = 6597



----------- Training Results ----------------
Started training at: 	2024-05-29  06:42:27
Ended training at: 	2024-05-29  07:01:16
Total training time:  0:18:49.222222
epoch count: 4317
end epsilon: 0.013297749874793902
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	6597

**Exited training loop early at episode 4317
start_episode = 4317



----------- Training Results ----------------
Started training at: 	2024-05-29  07:16:03
Ended training at: 	2024-05-29  09:46:15
Total training time:  2:30:11.505052
epoch count: 6828
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	64
		n_heads :	2
		ff_dim :	256
		n_layers :	2
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	20000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	4317

**Exited training loop early at episode 6828
start_episode = 6828



----------- Training Results ----------------
Started training at: 	2024-05-29  20:51:36
Ended training at: 	2024-05-29  20:51:55
Total training time:  0:00:19.390006
epoch count: 30
end epsilon: 0.9694605362958227
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	4
		ff_dim :	512
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	16
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	6828

**Exited training loop early at episode 30
start_episode = 30



----------- Training Results ----------------
Started training at: 	2024-05-29  20:52:08
Ended training at: 	2024-05-30  06:05:44
Total training time:  9:13:35.856809
epoch count: 26794
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	4
		ff_dim :	512
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	64
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	30

**Exited training loop early at episode 26794
start_episode = 26794



----------- Training Results ----------------
Started training at: 	2024-05-30  08:05:04
Ended training at: 	2024-05-30  08:26:13
Total training time:  0:21:09.135740
epoch count: 1127
end epsilon: 0.323497343674428
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	4
		ff_dim :	512
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	5000
		batch_size :	64
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	26794

**Exited training loop early at episode 1127
start_episode = 1127



----------- Training Results ----------------
Started training at: 	2024-05-30  08:26:19
Ended training at: 	2024-05-31  14:00:28
Total training time:  1 day, 5:34:08.755404
epoch count: 79999
end epsilon: 0.009998671593271896
Input Parameters:
		input_dim :	42
		embed_dim :	256
		n_heads :	2
		ff_dim :	256
		n_layers :	4
		output_dim :	7
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		num_epochs :	80000
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		start_episode :	1127



----------- Training Results ----------------
Started training at: 	2024-05-31  14:26:48
Ended training at: 	2024-05-31  19:05:58
Total training time:  4:39:09.712858
epoch count: 9999
end epsilon: 0.009998671593271896
Input Parameters:
		num_epochs :	10000
		embed_dim :	256
		n_heads :	2
		ff_dim :	256
		n_layers :	4
		dropout :	0.1
		capacity :	8000
		batch_size :	64
		gamma :	0.99
		learning_rate :	5e-05
		epsilon :	1.0
		epsilon_min :	0.01
		epsilon_decay :	0.999
		input_dim :	42
		output_dim :	7
		start_episode :	1127

