


#filename: h24_cnn.hyp

# used for RL training of DDQN for connect-four game play with CNN layers

start_episode = 26900
end_episode = 100002
max_replay_buffer_size = 1000000

agent1_learning_rate = 0.00025
agent2_learning_rate = 0.00025

# Convolutional layer configurations: (out_channels, kernel_size, stride)
cnn_a1 = [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]
cnn_a2 = [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]

# Fully connected layer dimensions for each agent
fc_a1 = [2688, 128, 64]
fc_a2 = [2688, 128, 64]

console_status_interval = 500
tensorboard_status_interval = 100
ckpt_interval = 2500

render_game_at = [1, 250001]

a1_epsilon_start = 0.9
a1_epsilon_end = 0.01
a2_epsilon_start = 0.9
a2_epsilon_end = 0.01

batch_size = 32
gamma = 0.99


----------------------- Notes: 

CNN Layer: (16, 3, 1, 1)
    16: This is the number of filters (or kernels) in the first convolutional layer. Each filter extracts different 
    features from the input image, such as edges, colors, or other textures.
    3: This represents the kernel size. The kernel is a 3x3 grid, which is the size of the filter that will be convolved 
    with the input.
    1: This is the stride of the convolution. The stride specifies how many pixels the filter should move after each 
    operation. A stride of 1 means the filter moves one pixel at a time.
    1: This is the padding. Padding of 1 means that one layer of zeros is added around the entire input feature map. 
    This is typically done to preserve the spatial dimensions of the input through the layer, so the output feature map 
    will have the same width and height as the input map if the stride is 1.


----------- Training Results ----------------
Started training at: 	2024-05-11  12:04:26
Ended training at: 	2024-05-11  12:25:13
Total training time:  0:20:46.249180
start_episode: 0
end_episode: 100002
Episode count: 13300
agent1 end epsilon: 0.4946681082109078
agent2 end epsilon: 0.4946681082109078
Draws: 0
Comp/Ratio Agent_1_to_Agent_2 Reward 1.2168222811670981
Ave steps per game: 23.00
total_loss1 / num_steps1: 0.10463645911830313
total_loss2 / num_steps2: 0.09130742181749905
agent1 lr: 0.00025
agent2 lr: 0.00025
gamma: 0.99
batch_size: 32
buffer_capacity: 1000000



----------- Training Results ----------------
Started training at: 	2024-05-11  12:25:52
Ended training at: 	2024-05-11  12:30:06
Total training time:  0:04:13.959998
start_episode: 0
end_episode: 100002
Episode count: 2800
agent1 end epsilon: 0.7934238873494629
agent2 end epsilon: 0.7934238873494629
Draws: 0
Comp/Ratio Agent_1_to_Agent_2 Reward 1.0539086102719013
Ave steps per game: 19.67
total_loss1 / num_steps1: 0.07592239305377006
total_loss2 / num_steps2: 0.1770113135377566
agent1 lr: 0.00025
agent2 lr: 0.00025
gamma: 0.99
batch_size: 32
buffer_capacity: 1000000



----------- Training Results ----------------
Started training at: 	2024-05-11  12:30:09
Ended training at: 	2024-05-11  14:25:47
Total training time:  1:55:37.973435
start_episode: 0
end_episode: 100002
Episode count: 79900
agent1 end epsilon: 0.024706682288821502
agent2 end epsilon: 0.024706682288821502
Draws: 0
Comp/Ratio Agent_1_to_Agent_2 Reward 1.6433555259660373
Ave steps per game: 14.82
total_loss1 / num_steps1: 0.05954020714852959
total_loss2 / num_steps2: 0.04748960832754771
agent1 lr: 0.00025
agent2 lr: 0.00025
gamma: 0.99
batch_size: 32
buffer_capacity: 1000000



----------- Training Results ----------------
Started training at: 	2024-05-11  14:33:48
Ended training at: 	2024-05-11  14:37:03
Total training time:  0:03:14.746106
start_episode: 0
end_episode: 100002
Episode count: 1900
A1 Convolutional layers: [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]
A2 Convolutional layers: [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]
A1 Fully connected layers: [2688, 256, 128, 64]
A2 Fully connected layers: [2688, 256, 128, 64]
agent1 end epsilon: 0.8262150512886066
agent2 end epsilon: 0.8262150512886066
Draws: 0
Comp/Ratio Agent_1_to_Agent_2 Reward 1.0320868516284685
Ave steps per game: 18.29
total_loss1 / num_steps1: 0.18065856261686844
total_loss2 / num_steps2: 0.1821722611784935
agent1 lr: 0.00025
agent2 lr: 0.00025
gamma: 0.99
batch_size: 32
buffer_capacity: 1000000



----------- Training Results ----------------
Started training at: 	2024-05-11  14:37:46
Ended training at: 	2024-05-11  15:18:43
Total training time:  0:40:57.780507
start_episode: 0
end_episode: 100002
Episode count: 26900
A1 Convolutional layers: [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]
A2 Convolutional layers: [(16, 3, 1, 1), (32, 3, 1, 1), (64, 3, 1, 1)]
A1 Fully connected layers: [2688, 256, 128, 64]
A2 Fully connected layers: [2688, 256, 128, 64]
agent1 end epsilon: 0.268251553652102
agent2 end epsilon: 0.268251553652102
Draws: 0
Comp/Ratio Agent_1_to_Agent_2 Reward 1.3278687182398523
Ave steps per game: 22.07
total_loss1 / num_steps1: 0.16646409879128138
total_loss2 / num_steps2: 0.1421696161851287
agent1 lr: 0.00025
agent2 lr: 0.00025
gamma: 0.99
batch_size: 32
buffer_capacity: 1000000

